{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3381541",
   "metadata": {},
   "source": [
    "# Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180728b3",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tue-bmd/ulsa/blob/main/docs/source/notebooks/agent/agent_example.ipynb)\n",
    "&nbsp;\n",
    "[![View on GitHub](https://img.shields.io/badge/GitHub-View%20Source-blue?logo=github)](https://github.com/tue-bmd/ulsa/blob/main/docs/source/notebooks/agent/agent_example.ipynb)\n",
    "&nbsp;\n",
    "[![Hugging Face model](https://img.shields.io/badge/Hugging%20Face-Model-yellow?logo=huggingface)](https://huggingface.co/zeahub/ulsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install zea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zea\n",
    "import jax\n",
    "import keras\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.ops import convert_to_numpy\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bbfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ulsa.agent import setup_agent, Recover, AgentMask, reset_agent_state\n",
    "from ulsa.pipeline import make_pipeline\n",
    "from ulsa.ops import lines_rx_apo, Squeeze, Copy\n",
    "from ulsa.utils import (\n",
    "    update_scan_for_polar_grid,\n",
    "    FOCUSED_TRANSMITS,\n",
    "    load_subsampled_data,\n",
    "    copy_transmits_from_scan,\n",
    "    get_subsampled_parameters,\n",
    "    precompute_dynamic_range,\n",
    "    scan_sequence,\n",
    ")\n",
    "from ulsa.io_utils import postprocess_agent_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3333974",
   "metadata": {},
   "source": [
    "We will work with the GPU if available, and initialize using `init_device` to pick the best available device. Also, (optionally), we will set the matplotlib style for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf76270",
   "metadata": {},
   "outputs": [],
   "source": [
    "zea.init_device(verbose=False)\n",
    "zea.visualize.set_mpl_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4250b",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c47280",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"data/raw_data\"\n",
    "file_path = \"/mnt/USBMD_datasets/2024_USBMD_cardiac_S51/HDF5/20240701_P1_A4CH_0001.hdf5\"\n",
    "file = zea.File(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7792a",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfba6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(42)\n",
    "agent_config = zea.Config.from_yaml(\"configs/cardiac_112_3_frames.yaml\")\n",
    "agent, _ = setup_agent(agent_config, seed, jit_mode=\"off\")  # the pipeline will jit\n",
    "\n",
    "n_actions = agent_config.action_selection.n_actions\n",
    "io_config = agent_config.io_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed24ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = file.scan()\n",
    "\n",
    "if \"cardiac\" in str(file.path):\n",
    "    scan = copy_transmits_from_scan(scan, FOCUSED_TRANSMITS)\n",
    "    update_scan_for_polar_grid(scan)\n",
    "\n",
    "scan.dynamic_range = agent_config.data.image_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a8d6c",
   "metadata": {},
   "source": [
    "## Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    data_type=data_type,\n",
    "    output_range=agent.input_range,\n",
    "    output_shape=agent_config.action_selection.shape,\n",
    "    action_selection_shape=agent_config.action_selection.shape,\n",
    ")\n",
    "pipeline.append(Squeeze(axis=-1))\n",
    "\n",
    "# For raw data we need to prepare some beamforming settings\n",
    "if data_type == \"data/raw_data\":\n",
    "    bandpass_rf = scipy.signal.firwin(\n",
    "        numtaps=128,\n",
    "        cutoff=np.array([0.5, 1.5]) * scan.center_frequency,\n",
    "        pass_zero=\"bandpass\",\n",
    "        fs=scan.sampling_frequency,\n",
    "    )\n",
    "    rx_apo = lines_rx_apo(scan.n_tx_total, scan.grid_size_z, scan.grid_size_x)\n",
    "    bandwidth = 2e6\n",
    "\n",
    "    params = pipeline.prepare_parameters(\n",
    "        scan=scan, bandpass_rf=bandpass_rf, rx_apo=rx_apo, bandwidth=bandwidth, minval=0\n",
    "    )\n",
    "    params |= precompute_dynamic_range(file, scan, params)\n",
    "else:\n",
    "    params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a639115",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 30\n",
    "data = load_subsampled_data(\n",
    "    file,\n",
    "    data_type,\n",
    "    slice(0, n_frames),\n",
    "    np.ones(agent_config.action_selection.n_possible_actions),\n",
    "    agent_config.action_selection.n_possible_actions,\n",
    ")\n",
    "targets = scan_sequence(data, pipeline, params)\n",
    "\n",
    "targets = postprocess_agent_results(\n",
    "    targets, io_config, scan_convert_order=0, image_range=[-1, 1]\n",
    ")\n",
    "\n",
    "fig, _ = zea.visualize.plot_image_grid(\n",
    "    targets[::2],\n",
    "    titles=[f\"t={t}\" for t in list(range(0, len(targets), 2))],\n",
    "    remove_axis=True,\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae40723",
   "metadata": {},
   "source": [
    "## Ultrasound pipeline + active perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    data_type=data_type,\n",
    "    output_range=agent.input_range,\n",
    "    output_shape=agent.input_shape,\n",
    "    action_selection_shape=agent_config.action_selection.shape,\n",
    ")\n",
    "\n",
    "# Make sure the subsampled measurements are masked in the right way\n",
    "pipeline.append(AgentMask())\n",
    "\n",
    "# Copy the measurement to another key\n",
    "pipeline.append(Copy(output_key=\"measurement\"))\n",
    "\n",
    "# Recover the subsampled data\n",
    "pipeline.append(Recover(agent, hard_projection=True))\n",
    "\n",
    "# Crop to the right shape\n",
    "post_process = keras.layers.CenterCrop(*agent_config.action_selection.shape)\n",
    "pipeline.append(zea.ops.Lambda(post_process))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150d141",
   "metadata": {},
   "source": [
    "## Active perception loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39315c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent state\n",
    "agent_state = reset_agent_state(agent, seed)\n",
    "params[\"agent_state\"] = agent_state\n",
    "selected_lines = agent_state.selected_lines\n",
    "\n",
    "# Initialize lists\n",
    "reconstructions = []\n",
    "measurements = []\n",
    "belief_distributions = []\n",
    "\n",
    "for i in tqdm(range(n_frames)):\n",
    "    selected_data = load_subsampled_data(file, data_type, i, selected_lines, n_actions)\n",
    "    subsampled_params = get_subsampled_parameters(\n",
    "        data_type, scan, selected_lines, rx_apo, n_actions\n",
    "    )\n",
    "    subsampled_params = pipeline.prepare_parameters(**subsampled_params)\n",
    "\n",
    "    # Skip some parameters from the scan class\n",
    "    subsampled_params.pop(\"dynamic_range\", None)\n",
    "\n",
    "    # Run pipeline\n",
    "    output = pipeline(data=selected_data, **{**params, **subsampled_params})\n",
    "\n",
    "    # Load data from the output\n",
    "    reconstruction = output[\"data\"]\n",
    "    selected_lines = output[\"agent_state\"].selected_lines\n",
    "\n",
    "    # Keep some keys for the next iteration\n",
    "    params[\"agent_state\"] = output[\"agent_state\"]\n",
    "\n",
    "    # Store the reconstruction\n",
    "    reconstructions.append(convert_to_numpy(reconstruction))\n",
    "    measurements.append(convert_to_numpy(output[\"measurement\"]))\n",
    "    belief_distributions.append(convert_to_numpy(output[\"agent_state\"].belief_distribution))\n",
    "\n",
    "reconstructions = np.stack(reconstructions)\n",
    "measurements = np.stack(measurements)\n",
    "belief_distributions = np.stack(belief_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = postprocess_agent_results(\n",
    "    np.squeeze(reconstructions, -1),\n",
    "    io_config,\n",
    "    scan_convert_order=0,\n",
    "    image_range=[-1, 1],\n",
    "    reconstruction_sharpness_std=io_config.get(\"reconstruction_sharpness_std\", 0.0),\n",
    ")\n",
    "measurements = postprocess_agent_results(\n",
    "    keras.ops.squeeze(post_process(measurements), -1),\n",
    "    io_config,\n",
    "    scan_convert_order=0,\n",
    "    image_range=[-1, 1],\n",
    ")\n",
    "variance = keras.ops.var(belief_distributions, axis=1)\n",
    "variance = convert_to_numpy(keras.ops.squeeze(post_process(variance), -1))\n",
    "variance = postprocess_agent_results(\n",
    "    variance,\n",
    "    io_config,\n",
    "    scan_convert_order=0,\n",
    "    image_range=[0, np.percentile(variance, 99.5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ims = zea.visualize.plot_image_grid(\n",
    "    [targets[0], measurements[0], reconstructions[0], variance[0]],\n",
    "    titles=[\"Target\", \"Measurements\", \"Reconstruction\", \"Variance\"],\n",
    "    ncols=4,\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    "    cmap=[\"gray\"] * 3 + [\"inferno\"],\n",
    "    figsize=(11, 4),\n",
    ")\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    ims[0].set_array(targets[frame])\n",
    "    ims[1].set_array(measurements[frame])\n",
    "    ims[2].set_array(reconstructions[frame])\n",
    "    ims[3].set_array(variance[frame])\n",
    "\n",
    "    return ims\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(targets), blit=True, interval=100)\n",
    "plt.close(fig)\n",
    "HTML(ani.to_jshtml(embed_frames=True, default_mode=\"loop\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
